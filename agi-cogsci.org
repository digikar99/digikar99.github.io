#+HTML_HEAD: <meta charset="utf-8">
#+HTML_HEAD: <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="others.css">
#+OPTIONS: toc:nil num:nil html-postamble:nil
#+TITLE: AGI and Cognitive Science - digikar99.github.io

#+BEGIN_CENTER
[[file:index.html#home][Home]] | [[file:common-lisp-and-emacs.html][Common Lisp and Emacs]] | *AGI AND COGNITIVE SCIENCE* | [[./digimon.html][Digimon]]
#+END_CENTER

#+TOC: headlines 1

#+html: <br>

* 0. Don't we already have AGI with GPT4 and DALL-E?

Empirically, the day an AI system is successful in supervising critical systems including cars on Indian roads, operation rooms, nuclear facilities - a separate system for each is acceptable(!) -  for decades on end without programmer supervision, that will perhaps be the day I will accept that we have an AGI. So long as there is a programmer in some part of the loop of maintaining an AI system, we don't have an AGI. The involvement of the programmer in the maintenance of a long-running computer system essentially gives the AI the freedom to be successful without good-enough models of the world. 

Until then, we will have AI systems that will have huge commercial success, systems that will solve 80% of our problems, systems that will amplify our power multiplicatively (not additively!). Perhaps, there might not even be any commercial incentive to the development of machines with full general intelligence that provide additive power the way your friends, colleagues, and lab-mates do.

* 1. Are there good reasons to develop an AGI? Wouldn't that be dangerous?

AI is dangerous as it is, in the hands of a super-powerful/wealthy minority or the military. In fact there already are efforts to decentralize AI. I think developing an AGI doesn't simply mean developing a more capable AI, but rather providing the machine with the means to escape the dangerous purposes (perhaps unintentionally even!) it was designed for.

Besides, even though our brains and minds and bodies are marvelous in certain aspects, they are miserable in some other aspects. Our bodies aren't the best instruments for venturing into outer space. Nor are our disconnected brains the best vessels in the digital age. Entire decades of experience are lost with the death of a human. It takes years to obtain mastery in specific fields.

But equally importantly, perhaps the understanding we obtain during the process of creating an AGI would provide us with better means to understand our own selves. Why do we have any experience at all if we can do all kinds of things during [[https://www.mayoclinic.org/diseases-conditions/sleepwalking/symptoms-causes/syc-20353506][sleeping]]?

* 2. What do you think is the best way to achieve AGI?

There seems to be a recurring idea that conceptualizing, categorizing, and reidentification are at the core of intelligence. Unless a system is able to reidentify new high-dimensional sensory data in terms of its previous sensations, every sensation of the system will be distinct and the system will be unable to make use of its previous knowledge and experience.

It's a puzzle to me what this reidentification should look like, or what forms conceptualization and categorization should take. Certain aspects seem clear that the traditional ways of categorization and classification based on closed world assumptions are insufficient. A mere open world assumption also does not suffice, because the way we categorize the same sensory experience depends on not just our own prior knowledge, but also on our goals and intentions. A relevant example concerning this is Necker's cube. The perceptual object (usually two) that one experiences, depends on which of the middle two vertices the observer focuses their attention on.

#+BEGIN_CENTER
#+ATTR_HTML: :style width:240px
[[file:images/necker.png]]
#+END_CENTER

However, we humans also have an uncanny ability to identify what the beliefs and intentions of another agent (human?) are by mere observation, also known as the Theory of Mind. This ability develops fairly early in life and, perhaps, also forms the basis of shared symbols enabling communication and learning from other agents. It's unclear whether internet-scale video and text data can help develop this ability.

Previously, I have felt the work on [[https://www.worldscientific.com/worldscibooks/10.1142/8665][Non-Axiomatic Logic]] and [[https://zenodo.org/record/7008/files/ANewConstructivistAI-FromManualMethodstoSelf-ConstructiveSystems.pdf][Self-Constructive Systems]] to be promising in the construction of AGI. However, on later reflection and discussion, it seems that the approaches are useful for high level cognition, but the problems of reidentification of sensory data seem to require different approaches.

Indeed, this is only what /I/ think is the "best" /at the time of this writing/. May be at a future point of time, I run into a better idea. If you run into a different idea which you feel or think is better than these, feel free to give that idea a go! Except, don't just stop at the idea, ideas are dime a dozen.

* 3. Should I pursue Cognitive Science if I want to pursue AGI?

To the extent that you have never taken courses on philosophy of science, philosophy of mind, I will certainly encourage pursuing Cognitive Science at a place with a strength in philosophical and computational methods.

If AGI is the focus, another suggestion would also be - as Tomasello has suggested - on looking at things through the lens of Ontogeny and Phylogeny. You could pick up his recent publication on [[https://mitpress.mit.edu/9780262047005/the-evolution-of-agency/][The Evolution of Agency]]. A reason for this is that developing a "baby AGI" - that can bootstrap into an "adult AGI" - seems easier (and safer?) than directly developing an "adult AGI". And when modern day cognitive science or its siblings study cognition, the focus is usually on how the cognition is in adult humans, and I think that makes it hard to separate out which aspects of cognition are inherent to having human level intelligence/consciousness and which aspects are inherent to being /that particular/ human or a human with /that particular background/.

* 4. I have a background in XYZ, can you recommend me something will lead to AGI?

I actually started out with taking a course on NLP, thinking that understanding language will be sufficient for developing an AGI. That led me to thinking about how human children acquire language without having any language apriori - and thus First Language Acquisition. I then got wrapped up in Computational Cognitive Science and Consciousness, because we seem to acquire language in the context of an "internal world" rather than in "complete isolation". In addition, from an evolutionary perspective, prelinguistic cognition feels more primitive than language from an evolutionary or phylogenetic perspective: think about cockroaches or rats.

There are other arguments for "Perception" coming /before/ "Representations", as well as Perception being a necessary condition for AGI. As such, something you can work on includes figuring out how your background relates to perception, as well as how perception integrates into NAL or Replicode systems.

* 5. Learning Resources

[[https://cis.temple.edu/~pwang/AGI-Curriculum.html][This]] is an AGI curriculum put forth by a well-esteemed AGI researcher.

Here is an alternative suggestion based on my experiences so far:

- School Education (expected 2 dedicated years):
  - Prerequisites: English, understanding of a 10/14 year old
- Computer Science (expected 2 dedicated years): [[https://teachyourselfcs.com/][teachyourselfcs.com]]
  - Prerequisites: English, Mathematics from the above resource, understanding of a 16/18 year old
- Blog Post: [[https://human9being9.wordpress.com/2022/01/22/cognitive-science-and-artificial-general-intelligence-bootstrapping-and-childhood-cognitive-development/][Cognitive Science and Artificial General Intelligence: Bootstrapping and Childhood Cognitive Development]]

Something more directly relevant to the discussions above includes:

- Dedicated 2 months: [[https://link.springer.com/book/9780387310732][Christopher Bishop's Pattern Recognition and Machine Learning]]
- Dedicated 1 month: [[https://www.goodreads.com/book/show/6296680-understanding-psychology-as-a-science][Diene's Understanding Psychology as a Science]]
- Dedicated 2 months: [[https://www.cambridge.org/core/journals/philosophy-of-science/article/abs/zenon-w-pylyshyn-computation-and-cognition-toward-a-foundation-for-cognitive-science-cambridge-ma-bradford-booksmit-press-1984-xxiii-292-pp-2500/830D21F75AC20AE4E5CA419E91A77C9D][Pylyshyn's Computation and Cognition: Toward a Foundation for Cognitive Science]]
- Dedicated 1 month: [[http://ruccs.rutgers.edu/images/personal-zenon-pylyshyn/nicodbook/Cognet_PDF/Pylyshyn_Things_all.pdf][Pylyshyn's Things and Places: How the Mind Connects with the World]]
- Dedicated 2 months: [[https://www.worldscientific.com/worldscibooks/10.1142/8665][Pei Wang's Non-Axiomatic Logic: A Model of Intelligent Reasoning]]

Other readings:
- /all/ of Pylyshyn's writings
- /all/ of Pei Wang's writings

*When I say "dedicated", it assumes you will be working full-time on the topic.
